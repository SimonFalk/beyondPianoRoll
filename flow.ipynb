{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f89d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import madmom\n",
    "\n",
    "from segment import segment_spectrogram\n",
    "from modules.labels import get_label_vector, shuffle_frames, get_label_table\n",
    "from modules.madmom_cnn_prep import cnn_preprocessor, cnn_normalize\n",
    "from datasets import Dataset\n",
    "from analyze_detection import evaluate, f_score\n",
    "from models.bock2013pret import get_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "SR = 44100\n",
    "FPS = 100\n",
    "CONTEXT = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ac37ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample rates are not equal to 44.1kHz!\n",
      "Some sample rates are not equal to 44.1kHz!\n",
      "Some sample rates are not equal to 44.1kHz!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/audio/signal.py:457: UserWarning: Deprecated as of version 0.16. Please use madmom.io.audio.load_wave_file instead. Will be removed in version 0.18.\n",
      "  warnings.warn('Deprecated as of version 0.16. Please use madmom.io.audio.'\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    }
   ],
   "source": [
    "ds0 = Dataset(\"initslurtest\")\n",
    "ds1 = Dataset(\"slurtest_add_1\")\n",
    "ds2 = Dataset(\"slurtest_add_2\")\n",
    "ds3 = Dataset(\"slurtest_test\")\n",
    "\n",
    "audio_fnames = ds0.get_audio_paths() + ds1.get_audio_paths() + ds2.get_audio_paths() + ds3.get_audio_paths()\n",
    "label_fnames = ds0.get_annotation_paths() + ds1.get_annotation_paths() + ds2.get_annotation_paths() + ds2.get_annotation_paths()\n",
    "\n",
    "\n",
    "audios = [madmom.audio.signal.load_wave_file(filename)[0] for filename in audio_fnames]\n",
    "sample_rates = [madmom.audio.signal.load_wave_file(filename)[1] for filename in audio_fnames]\n",
    "onset_schedules = [np.loadtxt(label_fname, usecols=0) for label_fname in label_fnames]\n",
    "for ele in sample_rates:\n",
    "    if ele != SR:\n",
    "        print(\"Some sample rates are not equal to 44.1kHz!\")\n",
    "\n",
    "# TODO move to mixed dataset (not based on recordings)\n",
    "# TODO investigate sample rate problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7d99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessing funciton\n",
    "preprocessor = cnn_preprocessor()\n",
    "box_processor = madmom.features.onsets.CNNOnsetProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3577bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/simonf/beyondPianoRoll/flow.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m audio\u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m             scale\u001b[39m=\u001b[39mmadmom\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39msignal\u001b[39m.\u001b[39mroot_mean_square(audio)\u001b[39m/\u001b[39m(\u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(p\u001b[39m/\u001b[39m\u001b[39m20\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m             size\u001b[39m=\u001b[39maudio\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m audio, fname \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(audios, audio_fnames):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/flow.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39;49m\u001b[39mdataset/augmented/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mbasename(fname) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_noise_SNRdB_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49mSNR_DB)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# Add white noise to recordings\n",
    "# Noise variance is adjusted to a fixed Signal Noise Ratio computed recording-wise\n",
    "# snr_db = 20 means S/N=10\n",
    "# snr_db = 10 means S/Nâ‰ˆ3.2\n",
    "SNR_DB = 10\n",
    "snr_v = 10**(SNR_DB/20)\n",
    "\n",
    "def augmentation(audio, t=None, p=None):\n",
    "    if t==None:\n",
    "        return audio\n",
    "    elif t==\"white_noise\":\n",
    "        # p contains snr_db parameter\n",
    "        return audio+np.random.normal(\n",
    "            scale=madmom.audio.signal.root_mean_square(audio)/(10**(p/20)),\n",
    "            size=audio.shape\n",
    "            )\n",
    "\n",
    "for audio, fname in zip(audios, audio_fnames):\n",
    "    np.save(\"dataset/augmented/\" + os.path.basename(fname) + \"_noise_SNRdB_\"+SNR_DB)\n",
    "\n",
    "# TODO enable augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_vectors = [get_label_vector(sched, len(audio)/sr, FPS)\n",
    "    for (sched, audio, sr) in zip(onset_schedules, audios, sample_rates)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6656f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    }
   ],
   "source": [
    "# Create data and normalize\n",
    "mm_proc_frames = [preprocessor(fname) for fname in audio_fnames]\n",
    "mm_frames_normalized = [cnn_normalize(frame_set) for frame_set in mm_proc_frames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7144fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    batch_size,\n",
    "    steps_per_epoch,\n",
    "    epochs,\n",
    "    idx, \n",
    "    sampling=True,\n",
    "    mode=None,\n",
    "    standard=False,\n",
    "    mean=None,\n",
    "    std=None, \n",
    "    single_channel=False\n",
    "):\n",
    "    \n",
    "    #for _ in range(steps_per_epoch * epochs):\n",
    "    if not sampling:\n",
    "        ep = 0\n",
    "        file_p = 0\n",
    "        frame_p = 0\n",
    "    \n",
    "    while True:\n",
    "        # Select indices for training or test\n",
    "        if sampling:\n",
    "            file_i = np.random.choice(idx)\n",
    "        else:\n",
    "            file_i = idx[file_p]\n",
    "        \n",
    "        #print(\"Selected file index: \", file_i)\n",
    "        fname = audio_fnames[file_i]\n",
    "        \n",
    "        if mode==\"use_prep_frames\":\n",
    "            frames = mm_frames_normalized[file_i]\n",
    "        elif mode==\"use_raw_frames\":\n",
    "            # No normalization\n",
    "            frames = mm_proc_frames[file_i]    \n",
    "        else:\n",
    "            # Compute frames\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                fxn()\n",
    "                frames = cnn_normalize(preprocessor(fname))\n",
    "\n",
    "        if standard:\n",
    "            frames = (frames-mean)/std\n",
    "            \n",
    "        #print(\"Frame size: \", frames.shape[0])\n",
    "\n",
    "        # Retrieve onsets \n",
    "        onsets = onset_vectors[file_i]\n",
    "        #print(\"Computed frames of size \", frames.shape)\n",
    "        #print(\"Onset vectors have len \", len(onsets))\n",
    "\n",
    "        # Sample a set of indices (defined from audio start,\n",
    "        # that is CONTEXT values counted from x array start)\n",
    "        if sampling:\n",
    "            focus_idx = np.random.choice(\n",
    "                np.arange(frames.shape[0]-2*CONTEXT-1), \n",
    "                size=batch_size\n",
    "            )\n",
    "            #print(\"Sampled focus idx between \", 0, \" and \", frames.shape[0]-2*CONTEXT-1)\n",
    "        else:\n",
    "            #print(\"Focus idx from \", frame_p, \" to \", frame_p+batch_size)\n",
    "            focus_idx = np.arange(frame_p, frame_p+batch_size)\n",
    "        \n",
    "\n",
    "        # Segmentation\n",
    "        x = [frames[focus:focus+2*CONTEXT+1,:,:] for focus in focus_idx]\n",
    "        if single_channel:\n",
    "            x = np.transpose(np.stack(x,0)[:,:,:,0], [0,2,1])\n",
    "        else:   \n",
    "            x = np.transpose(np.stack(x, 0), [0,2,1,3])\n",
    "        #print(\"Segmented x has shape \", x.shape)\n",
    "        if x.shape[0] != batch_size:\n",
    "            print(\"Delivering less than batch-size\")\n",
    "\n",
    "        # Labels\n",
    "        y = onsets[focus_idx]\n",
    "        yield (x, y)\n",
    "\n",
    "        if not sampling:\n",
    "            if frame_p + 2*batch_size >= frames.shape[0]-2*CONTEXT-1:\n",
    "                if file_p == len(idx) - 1:\n",
    "                    ep += 1\n",
    "                    print(\"Generator reached end of epoch. Resetting...\")\n",
    "                    file_p = 0\n",
    "                    frame_p = 0\n",
    "                else:\n",
    "                    file_p += 1\n",
    "                    frame_p = 0\n",
    "            else:\n",
    "                frame_p += batch_size\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab8a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom split:\n",
    "n_splits = 1\n",
    "split_at_rec = 18\n",
    "folds = [[np.arange(split_at_rec), np.arange(split_at_rec, len(audio_fnames))]]\n",
    "folds = [[[1], [2]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207926be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified by musician\n",
    "sa_recs = list(np.arange(19)) + [23, 25, 28, 32, 36, 37, 45, 46]\n",
    "fk_recs = [22, 29, 30, 33, 44, 47]\n",
    "ir_recs = np.setdiff1d(list(np.arange(49)), sa_recs + fk_recs)\n",
    "\n",
    "random_seed = 119\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "folds = list(skf.split(\n",
    "    np.concatenate((sa_recs, ir_recs)), # Indices in devset\n",
    "    np.concatenate((np.zeros(len(sa_recs)), np.ones(len(ir_recs)))) # Boolean whether recs are played by a certain musician\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bcc4b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold:\n",
    "random_seed = 119\n",
    "n_splits =  5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=True)\n",
    "folds = list(kf.split(np.arange(len(audio_fnames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89002ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute statistics\n",
    "means_per_fold = []\n",
    "std_per_fold = []\n",
    "onset_ratios = []\n",
    "for train_idx, test_idx in folds:\n",
    "    train_frames = np.concatenate([mm_proc_frames[i] for i in train_idx]) \n",
    "    mean_train = train_frames.mean(0)\n",
    "    std_train = train_frames.std(0, ddof=1)\n",
    "    means_per_fold.append(np.expand_dims(mean_train, axis=0))\n",
    "    std_per_fold.append(np.expand_dims(std_train, axis=0))\n",
    "\n",
    "#with open('results/computed/added_means_by_fold.pickle', 'wb') as file_pi:\n",
    "#    pickle.dump(means_per_fold, file_pi)\n",
    "#with open('results/computed/added_std_by_fold.pickle', 'wb') as file_pi:\n",
    "#    pickle.dump(std_per_fold, file_pi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b91d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steps(idx, bs):\n",
    "    song_sizes = np.array([len(f) for f in mm_proc_frames])[idx]-2*CONTEXT-1\n",
    "    steps_per_song = np.floor_divide(song_sizes, bs)\n",
    "    return np.sum(steps_per_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be42001",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"full\"\n",
    "continue_run = False\n",
    "training_mode = 0 # REMEMBER TO CHANGE\n",
    "check_at_epoch = None\n",
    "\n",
    "custom_model = False\n",
    "\n",
    "save = False # REMEMBER TO CHANGE\n",
    " # REMEMBER TO CHANGE\n",
    "save_path = \"results/cnn-training-220425/\" # TODO - automatically\n",
    "n_epochs = 10 # REMEMBER TO CHANGE\n",
    "learning_r = 0.0005\n",
    "bs = 256\n",
    "steps_per_epoch = int(np.sum(np.array([len(f) for f in mm_proc_frames])[folds[0][0]]-2*CONTEXT-1)/bs)\n",
    "val_steps_per_epoch = 100\n",
    "nogen = False\n",
    "sampling = False\n",
    "l2_lambda = 0 # DEFAULT: 0.01\n",
    "dropout_p = 0.0\n",
    "W = np.sum([len(vec) for vec in onset_vectors])/np.sum([vec.sum() for vec in onset_vectors])\n",
    "\n",
    "finetune = False\n",
    "\n",
    "standard = True # keep in mind on which data format statistics are computed \n",
    "mode = 'use_prep_frames' # Preparing by BN layer/\"CNN normalization\"\n",
    "mode = 'use_raw_frames' # No preparing\n",
    "\n",
    "\n",
    "training_name = \"{}-{}-{}eps-lr{:.4f}-{}\".format(\n",
    "    datasets, \n",
    "    \"nogen\" if nogen else (\"sample\" if sampling else \"seq\"),\n",
    "    n_epochs,\n",
    "    learning_r,\n",
    "    \"standard\" if standard else \"nostandard\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb961d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wbce(y_true, y_pred):\n",
    "    y_pred = tf.keras.backend.clip(y_pred, 1e-7, 1-1e-7)\n",
    "    logits = tf.keras.backend.log(y_pred/(1-y_pred))\n",
    "    return tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true, logits, W\n",
    "    )\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "metrics = [\n",
    "    wbce\n",
    "    #tf.keras.metrics.TruePositives(name='tp', thresholds=0.5),\n",
    "    #tf.keras.metrics.TrueNegatives(name='tn', thresholds=0.5),\n",
    "    #tf.keras.metrics.FalsePositives(name='fp', thresholds=0.5),\n",
    "    #tf.keras.metrics.FalseNegatives(name='fn', thresholds=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accf57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 14:46:44.304685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.318039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.318802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.320294: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 14:46:44.320882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.321616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.322381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.686148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.686505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.686766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 14:46:44.687009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4962 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(80, 15)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, \n",
    "            trainable = True,\n",
    "            activation = \"sigmoid\",\n",
    "            kernel_regularizer=l2(l2_lambda),\n",
    "            bias_regularizer=l2(l2_lambda)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(64, \n",
    "            trainable = True,\n",
    "            activation = \"sigmoid\",\n",
    "            kernel_regularizer=l2(l2_lambda),\n",
    "            bias_regularizer=l2(l2_lambda)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1, \n",
    "            activation = \"sigmoid\",\n",
    "            kernel_regularizer=l2(l2_lambda),\n",
    "            bias_regularizer=l2(l2_lambda)\n",
    "    )  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83087052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0/1 ---------\n",
      "Train indices:  [1]\n",
      "Test indices:  [2]\n"
     ]
    }
   ],
   "source": [
    "#if standard:\n",
    "#    with open('results/computed/added_means_by_fold.pickle', 'rb') as file_pi:\n",
    "#        means = pickle.load(file_pi)\n",
    "#    with open('results/computed/added_std_by_fold.pickle', 'rb') as file_pi:\n",
    "#        stds = pickle.load(file_pi)\n",
    "\n",
    "from numpy import single\n",
    "\n",
    "\n",
    "if isinstance(training_mode, int):\n",
    "    fold = training_mode\n",
    "else:\n",
    "    fold = 0\n",
    "\n",
    "while fold < n_splits:\n",
    "    print()\n",
    "    print(\"Fold {}/{} ---------\".format(fold, n_splits))\n",
    "    train_idx = folds[fold][0]\n",
    "    test_idx = folds[fold][1]\n",
    "    print(\"Train indices: \", train_idx)\n",
    "    print(\"Test indices: \", test_idx)\n",
    "\n",
    "    # Data\n",
    "    if nogen:\n",
    "        X_train, X_test = [\n",
    "            np.concatenate([X[i] for i in idx]) \n",
    "            for idx in (train_idx, test_idx)\n",
    "        ]\n",
    "        y_train, y_test = [\n",
    "            np.concatenate([onset_vectors[i] for i in idx]) \n",
    "            for idx in (train_idx, test_idx)\n",
    "        ]\n",
    "\n",
    "    #train_onset_ratio = y_train.sum()/len(y_train)\n",
    "\n",
    "    # Normalize with training set statistics\n",
    "    if standard:\n",
    "        mean = means_per_fold[fold]\n",
    "        std = std_per_fold[fold]\n",
    "    else:\n",
    "        mean, std = None, None\n",
    "\n",
    "    # Model\n",
    "    if not continue_run:\n",
    "        tf.keras.backend.clear_session()\n",
    "    if custom_model:\n",
    "        model = model \n",
    "    else:\n",
    "        (model, norm_layer)=get_model(finetune=finetune, l2_lambda=l2_lambda, dropout_p=dropout_p)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss_fn,\n",
    "                metrics=metrics)\n",
    "                \n",
    "    if not sampling:\n",
    "        steps_per_epoch = compute_steps(train_idx, bs)\n",
    "        val_steps_per_epoch = compute_steps(test_idx, bs)\n",
    "\n",
    "    if nogen:\n",
    "        x = X_train\n",
    "        y = y_train\n",
    "        steps_per_epoch = None\n",
    "        validation_data = (X_test, y_test)\n",
    "    else:\n",
    "        x = data_generator(\n",
    "            batch_size=bs, \n",
    "            steps_per_epoch=steps_per_epoch, \n",
    "            epochs=n_epochs,\n",
    "            idx=train_idx,\n",
    "            sampling=sampling,\n",
    "            mode=mode,\n",
    "            standard=standard, mean=mean, std=std,\n",
    "            single_channel=custom_model\n",
    "        )\n",
    "        y = None\n",
    "        validation_data = data_generator(\n",
    "            batch_size=bs, \n",
    "            steps_per_epoch=val_steps_per_epoch, \n",
    "            epochs=n_epochs,\n",
    "            idx=test_idx,\n",
    "            sampling=sampling,\n",
    "            mode=mode,\n",
    "            standard=standard, mean=mean, std=std,\n",
    "            single_channel=custom_model\n",
    "        )\n",
    "\n",
    "    checkpoint_path = save_path + 'fold_{}_{}'.format(fold,training_name)+\"_cp_{epoch:04d}.ckpt\"\n",
    "    if check_at_epoch is None:\n",
    "        cp_callback=[]\n",
    "    else:\n",
    "        cp_callback = [tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_freq=int(steps_per_epoch*check_at_epoch))]\n",
    "    # Training\n",
    "    \"\"\"\n",
    "    history = model.fit(\n",
    "        x = x, y = y, \n",
    "        steps_per_epoch = steps_per_epoch,\n",
    "        epochs          = n_epochs,\n",
    "        # Validation data\n",
    "        validation_data = validation_data,\n",
    "        validation_steps  = val_steps_per_epoch,\n",
    "        class_weight = {0:1, 1:W},\n",
    "        callbacks=cp_callback,\n",
    "        verbose=1\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "    # Saving\n",
    "    if save:\n",
    "        model.save(save_path + 'fold_{}_{}_model'.format(fold, training_name))\n",
    "        with open(save_path + 'fold_{}_{}_history.pickle'.format(fold, training_name), 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    \n",
    "    if training_mode != \"all\":\n",
    "        break\n",
    "    fold += 1\n",
    "\n",
    "# TODO change class weights - should not be hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "349ea602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f03e1c13490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['wbce'])\n",
    "plt.plot(history.history['val_wbce'])\n",
    "plt.legend([\"Training\", \"Validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd2013",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4fc909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

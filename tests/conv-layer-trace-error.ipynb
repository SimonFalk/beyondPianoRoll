{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import madmom\n",
    "import pickle\n",
    "from madmom.ml.nn import NeuralNetwork\n",
    "from copy import deepcopy\n",
    "from modules.madmom_cnn_prep import cnn_preprocessor\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float32\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_normalize(frames):\n",
    "    inv_std = np.load(\"models/bock2013pret_inv_std.npy\")\n",
    "    mean = np.load(\"models/bock2013pret_mean.npy\")\n",
    "    frames_normalized = (frames - np.reshape(mean, (1,80,3)))*np.reshape(inv_std, (1,80,3))\n",
    "    return frames_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# Preprocess and normalize - copied from MadMom\n",
    "preprocessor = cnn_preprocessor()\n",
    "frames = preprocessor(\"datasets/OnsetLabeledInstr2013/development/Violin/42954_FreqMan_hoochie_violin_pt1.wav\")\n",
    "frames_normalized = cnn_normalize(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<madmom.ml.nn.layers.BatchNormLayer at 0x14a30c5b0>,\n",
       " <madmom.ml.nn.layers.ConvolutionalLayer at 0x14a2ef850>,\n",
       " <madmom.ml.nn.layers.MaxPoolLayer at 0x148e7c250>,\n",
       " <madmom.ml.nn.layers.ConvolutionalLayer at 0x1499f0f70>,\n",
       " <madmom.ml.nn.layers.MaxPoolLayer at 0x149a24820>,\n",
       " <madmom.ml.nn.layers.StrideLayer at 0x149a246a0>,\n",
       " <madmom.ml.nn.layers.FeedForwardLayer at 0x149a24af0>,\n",
       " <madmom.ml.nn.layers.FeedForwardLayer at 0x14a31a7f0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Madmom model object\n",
    "with open('datasets/madmom_models-master/onsets/2013/onsets_cnn.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    mm_model = u.load()\n",
    "mm_model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=frames.shape),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            activation = 'tanh',\n",
    "            filters = 10,\n",
    "            kernel_size = (7,3),\n",
    "            strides = 1,\n",
    "            trainable = False\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "# Crucial step --- load weights from MadMom object\n",
    "\n",
    "my_model.layers[0].set_weights([\n",
    "    np.transpose(mm_model.layers[1].weights, [2,3,0,1]), \n",
    "    mm_model.layers[1].bias\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/madmom_models-master/onsets/2013/onsets_cnn.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    mm_model = u.load()\n",
    "\n",
    "# Process for altering MadMom model - create new pickle file\n",
    "# Keep only normalization layer\n",
    "\n",
    "mm_model.layers =[mm_model.layers[0]]\n",
    "with open('models/temp_model.pickle', 'wb') as file_pi:\n",
    "    pickle.dump(mm_model, file_pi)\n",
    "altered_nn = NeuralNetwork.load('models/temp_model.pickle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 80, 3) 60564.552902900556\n",
      "(1070, 80, 3) 60564.552902900556\n"
     ]
    }
   ],
   "source": [
    "# Compare\n",
    "arr1 = altered_nn(frames)\n",
    "arr2 = frames_normalized\n",
    "for arr in [arr1, arr2]:\n",
    "    print(arr.shape, arr.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/madmom_models-master/onsets/2013/onsets_cnn.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    mm_model = u.load()\n",
    "\n",
    "# Process for altering MadMom model - create new pickle file\n",
    "# Keep only normalization layer \n",
    "# + first convolution layer\n",
    "\n",
    "mm_model.layers = mm_model.layers[0:2]\n",
    "with open('models/temp_model.pickle', 'wb') as file_pi:\n",
    "    pickle.dump(mm_model, file_pi)\n",
    "altered_nn = NeuralNetwork.load('models/temp_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064, 78, 10) -445896.66\n",
      "(1064, 78, 10) -450595.38\n",
      "Sum of absolute difference:  343635.25\n"
     ]
    }
   ],
   "source": [
    "# Compare\n",
    "arr1 = my_model.predict(frames_normalized.reshape((1,-1,80,3))).reshape(-1,78,10)\n",
    "arr2 = altered_nn(frames)\n",
    "for arr in [arr1, arr2]:\n",
    "    print(arr.shape, arr.sum())\n",
    "\n",
    "print(\"Sum of absolute difference: \", np.sum(np.abs(arr1-arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of bias tensors before and after TF conversion:\n",
      "-11.930101\n",
      "-11.930101\n",
      "Sum of absolute difference:  0.0\n",
      "All close?  True\n"
     ]
    }
   ],
   "source": [
    "# Why are they different? Explore the biases and weights:\n",
    "\n",
    "w1 = mm_model.layers[1].bias\n",
    "w2 = my_model.layers[0].get_weights()[1]\n",
    "\n",
    "print(\"Sum of bias tensors before and after TF conversion:\")\n",
    "print(np.sum(w1))\n",
    "print(np.sum(w2))\n",
    "print(\"Sum of absolute difference: \", np.sum(np.abs(w1-w2)))\n",
    "print(\"All close? \", np.allclose(w1, w2, rtol=0, atol=1e-20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weight tensors before and after TF conversion:\n",
      "0.90992165\n",
      "0.90991974\n",
      "Sum of absolute difference:  0.0\n",
      "All close?  True\n"
     ]
    }
   ],
   "source": [
    "# Weigths:\n",
    "\n",
    "w1 = np.transpose(mm_model.layers[1].weights, [2,3,0,1])\n",
    "w2 = my_model.layers[0].get_weights()[0]\n",
    "\n",
    "print(\"Sum of weight tensors before and after TF conversion:\")\n",
    "print(np.sum(w1))\n",
    "print(np.sum(w2))\n",
    "print(\"Sum of absolute difference: \", np.sum(np.abs(w1-w2)))\n",
    "print(\"All close? \", np.allclose(w1, w2, rtol=0, atol=1e-20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

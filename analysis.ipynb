{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import madmom\n",
    "import mir_eval\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from modules.labels import get_label_vector\n",
    "from modules.madmom_cnn_prep import cnn_preprocessor\n",
    "from datasets import Dataset\n",
    "from modules.analysis_funcs import get_idx_to_fold, get_segmented_data, get_test_peaks, aubio_peakpicker_do, aubio_postprocessing\n",
    "from analyze_detection import evaluate\n",
    "from modules.energy_based import legato_mg, onsets_threshold_gate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FPS = 100\n",
    "CONTEXT = 7\n",
    "\n",
    "# Load Madmom normalization\n",
    "def cnn_normalize(frames):\n",
    "    inv_std = np.load(\"models/bock2013pret_inv_std.npy\")\n",
    "    mean = np.load(\"models/bock2013pret_mean.npy\")\n",
    "    frames_normalized = (frames - np.reshape(mean, (1,80,3)))*np.reshape(inv_std, (1,80,3))\n",
    "    return frames_normalized\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = madmom.audio.signal.FramedSignalProcessor(frame_size=2048, hop_size=441)\n",
    "stft = madmom.audio.stft.STFTProcessor()\n",
    "spect = madmom.audio.spectrogram.SpectrogramProcessor()\n",
    "proc = madmom.processors.SequentialProcessor([frame, stft, spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/audio/signal.py:457: UserWarning: Deprecated as of version 0.16. Please use madmom.io.audio.load_wave_file instead. Will be removed in version 0.18.\n",
      "  warnings.warn('Deprecated as of version 0.16. Please use madmom.io.audio.'\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    }
   ],
   "source": [
    "ds0 = Dataset(\"initslurtest\")\n",
    "ds1 = Dataset(\"slurtest_add_1\")\n",
    "\n",
    "audio_fnames = ds0.get_audio_paths() + ds1.get_audio_paths()\n",
    "label_fnames = ds0.get_annotation_paths() + ds1.get_annotation_paths()\n",
    "\n",
    "audios = [madmom.audio.signal.load_wave_file(filename)[0] for filename in audio_fnames]\n",
    "sample_rates = [madmom.audio.signal.load_wave_file(filename)[1] for filename in audio_fnames]\n",
    "onset_schedules = [np.loadtxt(label_fname, usecols=0) for label_fname in label_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3556419933217189\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "audio_lengths_sec = [len(audio)/sr for audio,sr in zip(audios, sample_rates)]\n",
    "iois = [np.ediff1d(onsets) for onsets in onset_schedules]\n",
    "ioi_spreads = [np.std(np.ediff1d(onsets)) for onsets in onset_schedules]\n",
    "onset_number = [len(onsets) for onsets in onset_schedules]\n",
    "mean_ioi = np.sum([np.sum(ioi) for ioi in iois])/np.sum(onset_number)\n",
    "print(mean_ioi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 119\n",
    "n_splits =  5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=True)\n",
    "kf_gen = list(kf.split(np.arange(len(audio_fnames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"results/cnn-training-220420/\"\n",
    "folds_path = base_path + \"folds.pkl\"\n",
    "\n",
    "model_name = \"added-seq-gen-nostandard\"\n",
    "\n",
    "folds = kf_gen\n",
    "#with open(folds_path, \"rb\") as f:\n",
    "    #folds = pickle.load(f)\n",
    "\n",
    "itf = get_idx_to_fold(folds)\n",
    "\n",
    "neural = False\n",
    "TOL = 0.025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_list = []\n",
    "FN_list = []\n",
    "FP_list = []\n",
    "for r in range(len(itf.keys())):\n",
    "    fold = itf[r]\n",
    "    rec_name = os.path.basename(audio_fnames[r])\n",
    "    x = get_segmented_data(audio_fnames[r])\n",
    "\n",
    "    model = tf.keras.models.load_model(base_path + \"fold_\" + str(fold) + \"_\" + model_name + \"_model\")\n",
    "    out = model.predict(x)\n",
    "    peaks = get_test_peaks(out, 1./FPS)\n",
    "    \n",
    "    [CD,FN,FP,doubles,merged] = evaluate(onset_schedules[r], peaks, tol_sec=TOL)\n",
    "    CD_list.append(CD)\n",
    "    FN_list.append(FN)\n",
    "    FP_list.append(FP)\n",
    "\n",
    "    scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "    print(rec_name + \"\\t\" + \"F-score: {:.2f}\".format(100*scores[\"F-measure\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.26315789473685\n",
      "19.88950276243094\n",
      "63.128491620111724\n",
      "56.92307692307692\n",
      "43.39622641509434\n",
      "6.862745098039215\n",
      "76.30057803468206\n",
      "66.19718309859154\n",
      "0.5162012023084546\n"
     ]
    }
   ],
   "source": [
    "# Only first fold\n",
    "#model = tf.keras.models.load_model(\"results/cnn-training-220409/fold_0_added-seq-gen-nostandard_model\")\n",
    "av_scores = []\n",
    "for r in folds[0][1]:\n",
    "    rec_name = os.path.basename(audio_fnames[r])\n",
    "    sig = madmom.audio.Signal(audio_fnames[r])\n",
    "    spect = madmom.audio.spectrogram.Spectrogram(audio_fnames[r])\n",
    "    hfc = madmom.features.onsets.high_frequency_content(spect)\n",
    "    onehot, out = aubio_peakpicker_do(hfc, threshold=0.15)\n",
    "    peaks = aubio_postprocessing(onehot, sig, db_thres=-90, min_ioi_frames=6)/FPS\n",
    "    \n",
    "    #x = get_segmented_data(audio_fnames[r])\n",
    "    #out = model.predict(x)\n",
    "    #peaks = get_test_peaks(out, 1./FPS)\n",
    "    scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "    print(scores[\"F-measure\"]*100)\n",
    "    av_scores.append(scores[\"F-measure\"])\n",
    "print(np.mean(av_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "slurtest04.wav\tF-score: 94.19\n",
      "slurtest18.wav\tF-score: 55.26\n",
      "stormhatten_IR2.wav\tF-score: 83.33\n",
      "slurtest01_IR2.wav\tF-score: 93.02\n",
      "6xtpsg_220319.wav\tF-score: 82.68\n",
      "6xtpsg_220306.wav\tF-score: 79.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurtest04_FK1.wav\tF-score: 95.36\n",
      "slurtest03_IR1.wav\tF-score: 90.91\n",
      "Fold 0    average F-score 84.26\n",
      "\n",
      "1\n",
      "slurtest05.wav\tF-score: 81.01\n",
      "slurtest04_IR2.wav\tF-score: 95.36\n",
      "melodyvib_220319.wav\tF-score: 62.44\n",
      "slurtest09_IR2.wav\tF-score: 87.67\n",
      "janissa_IR2.wav\tF-score: 73.26\n",
      "slurtest01_FK1.wav\tF-score: 88.37\n",
      "slurtest08_FK1.wav\tF-score: 97.92\n",
      "Fold 1    average F-score 83.72\n",
      "\n",
      "2\n",
      "slurtest03.wav\tF-score: 91.47\n",
      "slurtest11.wav\tF-score: 61.54\n",
      "slurtest15.wav\tF-score: 87.00\n",
      "slurtest02_IR1.wav\tF-score: 95.31\n",
      "slurtest03_FK1.wav\tF-score: 95.24\n",
      "slurtest01_IR1.wav\tF-score: 87.50\n",
      "63an_start_220306.wav\tF-score: 84.02\n",
      "Fold 2    average F-score 86.01\n",
      "\n",
      "3\n",
      "slurtest02.wav\tF-score: 93.85\n",
      "slurtest07.wav\tF-score: 93.93\n",
      "slurtest08.wav\tF-score: 95.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurtest14.wav\tF-score: 86.24\n",
      "slurtest17.wav\tF-score: 61.16\n",
      "slurtest19.wav\tF-score: 93.89\n",
      "stormhatten_IR1.wav\tF-score: 89.80\n",
      "Fold 3    average F-score 87.71\n",
      "\n",
      "4\n",
      "slurtest01.wav\tF-score: 88.06\n",
      "slurtest06.wav\tF-score: 95.28\n",
      "slurtest09.wav\tF-score: 86.09\n",
      "slurtest10.wav\tF-score: 44.44\n",
      "slurtest12.wav\tF-score: 69.88\n",
      "slurtest13.wav\tF-score: 88.17\n",
      "slurtest16.wav\tF-score: 85.38\n",
      "Fold 4    average F-score 79.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CD_list = []\n",
    "FN_list = []\n",
    "FP_list = []\n",
    "for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "    print(fold)\n",
    "    fold_average = []\n",
    "    for r in test_idx:\n",
    "        rec_name = os.path.basename(audio_fnames[r])\n",
    "        sig = madmom.audio.Signal(audio_fnames[r])\n",
    "        x = get_segmented_data(audio_fnames[r])\n",
    "        model = tf.keras.models.load_model(base_path + \"fold_\" + str(fold) + \"_\" + model_name + \"_model\")\n",
    "        out = model.predict(x)\n",
    "        peaks = get_test_peaks(out, 1./FPS)\n",
    "        \n",
    "        [CD,FN,FP,doubles,merged] = evaluate(onset_schedules[r], peaks, tol_sec=TOL)\n",
    "        CD_list.append(CD)\n",
    "        FN_list.append(FN)\n",
    "        FP_list.append(FP)\n",
    "\n",
    "        scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "        print(rec_name + \"\\t\" + \"F-score: {:.2f}\".format(100*scores[\"F-measure\"]))\n",
    "        fold_average.append(scores[\"F-measure\"])\n",
    "    print(\"Fold {}    average F-score {:.2f}\".format(fold, 100*np.mean(fold_average)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8609198567887634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(CD_list)/(np.sum(CD_list)+.5*(np.sum(FP_list) + np.sum(FN_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

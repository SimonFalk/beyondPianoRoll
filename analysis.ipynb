{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import madmom\n",
    "import mir_eval\n",
    "\n",
    "from modules.labels import get_label_vector\n",
    "from modules.madmom_cnn_prep import cnn_preprocessor\n",
    "from datasets import Dataset\n",
    "from modules.analysis_funcs import get_idx_to_fold, get_segmented_data, get_test_peaks\n",
    "from analyze_detection import evaluate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FPS = 100\n",
    "CONTEXT = 7\n",
    "\n",
    "# Load Madmom normalization\n",
    "def cnn_normalize(frames):\n",
    "    inv_std = np.load(\"models/bock2013pret_inv_std.npy\")\n",
    "    mean = np.load(\"models/bock2013pret_mean.npy\")\n",
    "    frames_normalized = (frames - np.reshape(mean, (1,80,3)))*np.reshape(inv_std, (1,80,3))\n",
    "    return frames_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = madmom.audio.signal.FramedSignalProcessor(frame_size=2048, hop_size=441)\n",
    "stft = madmom.audio.stft.STFTProcessor()\n",
    "spect = madmom.audio.spectrogram.SpectrogramProcessor()\n",
    "proc = madmom.processors.SequentialProcessor([frame, stft, spect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/audio/signal.py:457: UserWarning: Deprecated as of version 0.16. Please use madmom.io.audio.load_wave_file instead. Will be removed in version 0.18.\n",
      "  warnings.warn('Deprecated as of version 0.16. Please use madmom.io.audio.'\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    }
   ],
   "source": [
    "ds0 = Dataset(\"initslurtest\")\n",
    "ds1 = Dataset(\"slurtest_add_1\")\n",
    "\n",
    "audio_fnames = ds0.get_audio_paths() + ds1.get_audio_paths()\n",
    "label_fnames = ds0.get_annotation_paths() + ds1.get_annotation_paths()\n",
    "\n",
    "audios = [madmom.audio.signal.load_wave_file(filename)[0] for filename in audio_fnames]\n",
    "sample_rates = [madmom.audio.signal.load_wave_file(filename)[1] for filename in audio_fnames]\n",
    "onset_schedules = [np.loadtxt(label_fname, usecols=0) for label_fname in label_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"results/cnn-training-220409/\"\n",
    "folds_path = base_path + \"folds.pkl\"\n",
    "\n",
    "model_name = \"added-sample-gen-nostandard\"\n",
    "\n",
    "with open(folds_path, \"rb\") as f:\n",
    "    folds = pickle.load(f)\n",
    "\n",
    "itf = get_idx_to_fold(folds)\n",
    "\n",
    "neural = False\n",
    "TOL = 0.025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurtest01.wav\tF-score: 0.00\n",
      "slurtest02.wav\tF-score: 0.55\n",
      "slurtest03.wav\tF-score: 0.00\n",
      "slurtest04.wav\tF-score: 0.56\n",
      "slurtest05.wav\tF-score: 0.53\n",
      "slurtest06.wav\tF-score: 0.63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/simonf/beyondPianoRoll/analysis.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/analysis.ipynb#ch0000003vscode-remote?line=4'>5</a>\u001b[0m fold \u001b[39m=\u001b[39m itf[r]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/analysis.ipynb#ch0000003vscode-remote?line=5'>6</a>\u001b[0m rec_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(audio_fnames[r])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/analysis.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m get_segmented_data(audio_fnames[r])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/analysis.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m neural:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.67.120/home/simonf/beyondPianoRoll/analysis.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m     model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(base_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfold_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(fold) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/beyondPianoRoll/modules/analysis_funcs.py:23\u001b[0m, in \u001b[0;36mget_segmented_data\u001b[0;34m(path, CONTEXT)\u001b[0m\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=17'>18</a>\u001b[0m frames \u001b[39m=\u001b[39m cnn_normalize(frames)\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=19'>20</a>\u001b[0m     frames[i\u001b[39m-\u001b[39mCONTEXT:i\u001b[39m+\u001b[39mCONTEXT\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,:,:] \n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(CONTEXT, frames\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mCONTEXT)\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=21'>22</a>\u001b[0m ]\n\u001b[0;32m---> <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack(x, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=23'>24</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(x, [\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[1;32m     <a href='file:///home/simonf/beyondPianoRoll/modules/analysis_funcs.py?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py:424\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=420'>421</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m arrays:\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=421'>422</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mneed at least one array to stack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=423'>424</a>\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=424'>425</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=425'>426</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py:424\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=420'>421</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m arrays:\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=421'>422</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mneed at least one array to stack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=423'>424</a>\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39;49mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=424'>425</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/simonf/.venv/onsets/lib/python3.8/site-packages/numpy/core/shape_base.py?line=425'>426</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CD_list = []\n",
    "FN_list = []\n",
    "FP_list = []\n",
    "for r in range(len(itf.keys())):\n",
    "    fold = itf[r]\n",
    "    rec_name = os.path.basename(audio_fnames[r])\n",
    "    x = get_segmented_data(audio_fnames[r])\n",
    "    if neural:\n",
    "        model = tf.keras.models.load_model(base_path + \"fold_\" + str(fold) + \"_\" + model_name + \"_model\")\n",
    "        out = model.predict(x)\n",
    "        peaks = get_test_peaks(out, 1./FPS)\n",
    "    else:\n",
    "        spectrogram = proc(audios[r])\n",
    "        peaks = madmom.features.onsets.peak_picking(\n",
    "                                        activations=out, \n",
    "                                        threshold=0.01\n",
    "    )\n",
    "    \n",
    "    \n",
    "    [CD,FN,FP,doubles,merged] = evaluate(onset_schedules[r], peaks, tol_sec=TOL)\n",
    "    CD_list.append(CD)\n",
    "    FN_list.append(FN)\n",
    "    FP_list.append(FP)\n",
    "\n",
    "    scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "    print(rec_name + \"\\t\" + \"F-score: {:.2f}\".format(100*scores[\"F-measure\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505654281098546"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(CD_list)/(np.sum(CD_list)+.5*(np.sum(FP_list) + np.sum(FN_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

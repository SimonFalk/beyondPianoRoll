{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 16,
>>>>>>> 3df88b39fa7b7d02bc21aec8c2c503c891aa2169
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of datasets failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 983, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 913, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/simonfal/kth-master/exjobb/beyondPianoRoll/datasets/__init__.py\", line 63\n",
      "    class Dataset:\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import madmom\n",
    "import mir_eval\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from modules.labels import get_label_vector\n",
    "from modules.madmom_cnn_prep import cnn_preprocessor\n",
    "from datasets import Dataset\n",
    "from modules.analysis_funcs import get_idx_to_fold, get_segmented_data, get_test_peaks\n",
    "from analyze_detection import evaluate\n",
    "from modules.energy_based import legato_mg, onsets_threshold_gate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FPS = 100\n",
    "CONTEXT = 7\n",
    "\n",
    "# Load Madmom normalization\n",
    "def cnn_normalize(frames):\n",
    "    inv_std = np.load(\"models/bock2013pret_inv_std.npy\")\n",
    "    mean = np.load(\"models/bock2013pret_mean.npy\")\n",
    "    frames_normalized = (frames - np.reshape(mean, (1,80,3)))*np.reshape(inv_std, (1,80,3))\n",
    "    return frames_normalized\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 17,
>>>>>>> 3df88b39fa7b7d02bc21aec8c2c503c891aa2169
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = madmom.audio.signal.FramedSignalProcessor(frame_size=2048, hop_size=441)\n",
    "stft = madmom.audio.stft.STFTProcessor()\n",
    "spect = madmom.audio.spectrogram.SpectrogramProcessor()\n",
    "proc = madmom.processors.SequentialProcessor([frame, stft, spect])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 33,
>>>>>>> 3df88b39fa7b7d02bc21aec8c2c503c891aa2169
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/audio/signal.py:457: UserWarning: Deprecated as of version 0.16. Please use madmom.io.audio.load_wave_file instead. Will be removed in version 0.18.\n",
      "  warnings.warn('Deprecated as of version 0.16. Please use madmom.io.audio.'\n",
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    }
   ],
   "source": [
    "ds0 = Dataset(\"initslurtest\")\n",
    "ds1 = Dataset(\"slurtest_add_1\")\n",
    "ds2 = Dataset(\"slurtest_add_2\")\n",
    "\n",
    "audio_fnames = ds2.get_audio_paths() #+ ds1.get_audio_paths()\n",
    "#label_fnames = ds1.get_annotation_paths() #+ ds1.get_annotation_paths()\n",
    "\n",
    "audios = [madmom.audio.signal.load_wave_file(filename)[0] for filename in audio_fnames]\n",
    "sample_rates = [madmom.audio.signal.load_wave_file(filename)[1] for filename in audio_fnames]\n",
<<<<<<< HEAD
    "onset_schedules = [np.loadtxt(label_fname, usecols=0) for label_fname in label_fnames]"
=======
    "#onset_schedules = [np.loadtxt(label_fname, usecols=0) for label_fname in label_fnames]"
>>>>>>> 3df88b39fa7b7d02bc21aec8c2c503c891aa2169
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 35,
>>>>>>> 3df88b39fa7b7d02bc21aec8c2c503c891aa2169
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "8.819142526455026 s\n",
      "49.14855158730156\n",
      "1380\n",
      "40.70373473748474\n",
      "0.4011483079710145\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "audio_lengths_sec = [len(audio)/sr for audio,sr in zip(audios, sample_rates)]\n",
    "#iois = [np.ediff1d(onsets) for onsets in onset_schedules]\n",
    "#ioi_spreads = [np.std(np.ediff1d(onsets)) for onsets in onset_schedules]\n",
    "#onset_number = [len(onsets) for onsets in onset_schedules]\n",
    "#mean_ioi = np.sum([np.sum(ioi) for ioi in iois])/np.sum(onset_number)\n",
    "print(len(audios))\n",
    "print(np.sum(audio_lengths_sec)/60, \"s\")\n",
    "print(.819142526455026*60)\n",
    "print(np.sum(onset_number))\n",
    "print(np.mean(audio_lengths_sec))\n",
    "print(mean_ioi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 119\n",
    "n_splits =  5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=True)\n",
    "kf_gen = list(kf.split(np.arange(len(audio_fnames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"results/cnn-training-220409/\"\n",
    "folds_path = base_path + \"folds.pkl\"\n",
    "\n",
    "model_name = \"added-sample-gen-nostandard\"\n",
    "\n",
    "folds = kf_gen\n",
    "#with open(folds_path, \"rb\") as f:\n",
    "    #folds = pickle.load(f)\n",
    "\n",
    "itf = get_idx_to_fold(folds)\n",
    "\n",
    "neural = True\n",
    "TOL = 0.025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_list = []\n",
    "FN_list = []\n",
    "FP_list = []\n",
    "for r in range(len(itf.keys())):\n",
    "    fold = itf[r]\n",
    "    rec_name = os.path.basename(audio_fnames[r])\n",
    "    x = get_segmented_data(audio_fnames[r])\n",
    "    if neural:\n",
    "        model = tf.keras.models.load_model(base_path + \"fold_\" + str(fold) + \"_\" + model_name + \"_model\")\n",
    "        out = model.predict(x)\n",
    "        peaks = get_test_peaks(out, 1./FPS)\n",
    "    else:\n",
    "        leg_on, leg_val = legato_mg(audio_fnames[r], rel_delta=0.2)\n",
    "        peaks = onsets_threshold_gate(leg_on, leg_val, 1.0)\n",
    "    \n",
    "    [CD,FN,FP,doubles,merged] = evaluate(onset_schedules[r], peaks, tol_sec=TOL)\n",
    "    CD_list.append(CD)\n",
    "    FN_list.append(FN)\n",
    "    FP_list.append(FP)\n",
    "\n",
    "    scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "    print(rec_name + \"\\t\" + \"F-score: {:.2f}\".format(100*scores[\"F-measure\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.13924050632912\n",
      "60.86956521739131\n",
      "84.96732026143792\n",
      "93.0232558139535\n",
      "85.0574712643678\n",
      "78.88888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonf/.venv/onsets/lib/python3.8/site-packages/madmom/io/audio.py:493: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  file_sample_rate, signal = wavfile.read(filename, mmap=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.11764705882352\n",
      "93.75\n"
     ]
    }
   ],
   "source": [
    "# Only first fold\n",
    "model = tf.keras.models.load_model(\"results/cnn-training-220409/fold_0_added-seq-gen-nostandard_model\")\n",
    "for r in folds[0][1]:\n",
    "    rec_name = os.path.basename(audio_fnames[r])\n",
    "    x = get_segmented_data(audio_fnames[r])\n",
    "    \n",
    "    out = model.predict(x)\n",
    "    peaks = get_test_peaks(out, 1./FPS)\n",
    "    scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "    print(scores[\"F-measure\"]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:23:26.029841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/simonf/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "CD_list = []\n",
    "FN_list = []\n",
    "FP_list = []\n",
    "for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "    print(fold)\n",
    "    fold_average = []\n",
    "    for r in test_idx:\n",
    "        rec_name = os.path.basename(audio_fnames[r])\n",
    "        x = get_segmented_data(audio_fnames[r])\n",
    "        if neural:\n",
    "            model = tf.keras.models.load_model(base_path + \"fold_\" + str(fold) + \"_\" + model_name + \"_model\")\n",
    "            out = model.predict(x)\n",
    "            peaks = get_test_peaks(out, 1./FPS)\n",
    "        else:\n",
    "            leg_on, leg_val = legato_mg(audio_fnames[r], rel_delta=0.2)\n",
    "            peaks = onsets_threshold_gate(leg_on, leg_val, 1.0)\n",
    "        \n",
    "        [CD,FN,FP,doubles,merged] = evaluate(onset_schedules[r], peaks, tol_sec=TOL)\n",
    "        CD_list.append(CD)\n",
    "        FN_list.append(FN)\n",
    "        FP_list.append(FP)\n",
    "\n",
    "        scores = mir_eval.onset.evaluate(onset_schedules[r], peaks, window=TOL)\n",
    "        print(rec_name + \"\\t\" + \"F-score: {:.2f}\".format(100*scores[\"F-measure\"]))\n",
    "        fold_average.append(scores[\"F-measure\"])\n",
    "    print(\"Fold {}    average F-score {:.2f}\".format(fold, 100*np.mean(fold_average)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505654281098546"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(CD_list)/(np.sum(CD_list)+.5*(np.sum(FP_list) + np.sum(FN_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
